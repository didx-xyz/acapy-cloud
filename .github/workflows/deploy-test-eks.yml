name: Deploy and Test EKS

on:
  workflow_dispatch:
    inputs:
      image-version:
        description: Image version to deploy
        required: false
        default: latest
        type: string
      reset-deployments:
        description: Reset deployments - Clean start
        required: false
        default: false
        type: boolean
      run-e2e-tests:
        description: Run End-to-End Tests
        required: false
        default: true
        type: boolean
      run-k6-tests:
        description: Run K6 Tests
        required: false
        default: true
        type: boolean
      run-regression-tests:
        description: Run Regression Tests
        required: false
        default: true
        type: boolean
  workflow_call:
    inputs:
      acapy-helmfile-path:
        description: Path to the acapy helmfile to use
        required: false
        type: string
        default: ./helm/acapy-cloud.yaml.gotmpl
      acapy-test-helmfile-path:
        description: Path to the acapy test helmfile to use
        required: false
        type: string
        default: ./helm/acapy-test.yaml.gotmpl
      connect-configs-dir:
        description: The directory containing the Redpanda Connect configurations
        required: false
        type: string
        default: ./resources/connect-processors/cloud
      helm-plugins:
        description: Helmfile plugins to install
        required: false
        type: string
        default: https://github.com/databus23/helm-diff
      helm-version:
        description: Helm version to use
        required: true
        type: string
      helmfile-version:
        description: Helmfile version to use
        required: true
        type: string
      image-version:
        description: Image version to deploy
        required: true
        type: string
      namespace:
        description: Kubernetes namespace to deploy to
        required: false
        default: acapy-cloud-dev
        type: string
      reset-deployments:
        description: Reset deployment - Clean start
        required: false
        default: false
        type: boolean
      run-e2e-tests:
        description: Run End-to-End Tests
        required: false
        default: true
        type: boolean
      run-k6-tests:
        description: Run K6 Tests
        required: false
        default: true
        type: boolean
      run-regression-tests:
        description: Run Regression Tests
        required: false
        default: true
        type: boolean
      tailscale-tags:
        description: Tailscale device tags to use
        required: false
        default: "tag:cloudapi-dev"
        type: string
    secrets:
      tailscale-oauth-client-id:
        required: true
      tailscale-oauth-secret:
        required: true

permissions: {}

concurrency:
  group: deploy-test-eks
  cancel-in-progress: false

env:
  HELM_VERSION_DEFAULT: v3.18.1
  HELMFILE_VERSION_DEFAULT: v1.1.0

jobs:
  deploy:
    name: Deploy
    runs-on: ubuntu-latest

    timeout-minutes: 30

    environment:
      name: dev

    permissions:
      id-token: write # Required to authenticate with AWS

    steps:
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: false

      - name: Connect to EKS
        uses: didx-xyz/workflows/connect-eks@db85590d7cdd99f3eb257b0526d905263eca8499 # master
        with:
          aws-region: af-south-1
          aws-role-arn: arn:aws:iam::402177810328:role/cicd
          aws-role-session-name: github-cicd
          cluster-name: cloudapi-dev
          tailscale-oauth-client-id: ${{ secrets.tailscale-oauth-client-id || secrets.TAILSCALE_OAUTH_CLIENT_ID }}
          tailscale-oauth-secret: ${{ secrets.tailscale-oauth-secret || secrets.TAILSCALE_OAUTH_SECRET }}
          tailscale-tags: ${{ inputs.tailscale-tags || vars.TAILSCALE_TAGS }}

      - name: Helmfile Destroy
        if: inputs.reset-deployments
        # https://github.com/helmfile/helmfile-action
        uses: helmfile/helmfile-action@712000e3d4e28c72778ecc53857746082f555ef3 # v2.0.4
        with:
          helmfile-args: |
            destroy \
              --environment ${{ vars.ENVIRONMENT }} \
              -f ${{ inputs.acapy-helmfile-path || './helm/acapy-cloud.yaml.gotmpl' }} \
              --state-values-set namespace=${{ inputs.namespace || 'acapy-cloud-dev' }}
          helm-plugins: ${{ inputs.helm-plugins || 'https://github.com/databus23/helm-diff' }}
          helmfile-version: ${{ inputs.helmfile-version || env.HELMFILE_VERSION_DEFAULT }}
          helm-version: ${{ inputs.helm-version || env.HELM_VERSION_DEFAULT }}

      - name: Create Redpanda Connect Stream ConfigMap
        shell: bash
        # https://docs.redpanda.com/redpanda-connect/get-started/quickstarts/helm-chart/#run-multiple-pipelines-in-streams-mode
        run: |
          kubectl create configmap connect-cloud-pipelines \
            --from-file=${CONFIGS_DIR}/pipelines \
            --dry-run=client \
            -o yaml \
            -n $NAMESPACE | kubectl apply -f -
          kubectl create configmap connect-cloud-resources \
            --from-file=${CONFIGS_DIR}/resources \
            --dry-run=client \
            -o yaml \
            -n $NAMESPACE | kubectl apply -f -
          kubectl -n $NAMESPACE rollout restart deploy/connect-cloud || true
        env:
          NAMESPACE: ${{ inputs.namespace || 'acapy-cloud-dev' }}
          CONFIGS_DIR: ${{ inputs.connect-configs-dir || './resources/connect-processors/cloud' }}

      - name: Helmfile Apply
        # https://github.com/helmfile/helmfile-action
        uses: helmfile/helmfile-action@712000e3d4e28c72778ecc53857746082f555ef3 # v2.0.4
        with:
          helmfile-args: |
            apply \
              --environment ${{ vars.ENVIRONMENT }} \
              -f ${{ inputs.acapy-helmfile-path || './helm/acapy-cloud.yaml.gotmpl' }} \
              --state-values-set image.tag=${{ inputs.image-version }} \
              --state-values-set image.registry=ghcr.io/${{ github.repository_owner }} \
              --state-values-set pgProxyEnabled=${{ inputs.reset-deployments == false }} \
              --state-values-set namespace=${{ inputs.namespace || 'acapy-cloud-dev' }}
          helm-plugins: ${{ inputs.helm-plugins || 'https://github.com/databus23/helm-diff' }}
          helmfile-version: ${{ inputs.helmfile-version || env.HELMFILE_VERSION_DEFAULT }}
          helm-version: ${{ inputs.helm-version || env.HELM_VERSION_DEFAULT }}

  test-e2e:
    name: Tests / End-to-End
    needs: deploy
    if: inputs.run-e2e-tests
    runs-on: ubuntu-latest

    timeout-minutes: 30

    environment:
      name: dev

    permissions:
      id-token: write # Required to authenticate with AWS
      checks: write # Required for action-junit-report
      pull-requests: write # Required to comment on PRs for Pytest coverage comment

    steps:
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: false

      - name: Connect to EKS
        uses: didx-xyz/workflows/connect-eks@db85590d7cdd99f3eb257b0526d905263eca8499 # master
        with:
          aws-region: af-south-1
          aws-role-arn: arn:aws:iam::402177810328:role/cicd
          aws-role-session-name: github-cicd
          cluster-name: cloudapi-dev
          tailscale-oauth-client-id: ${{ secrets.tailscale-oauth-client-id || secrets.TAILSCALE_OAUTH_CLIENT_ID }}
          tailscale-oauth-secret: ${{ secrets.tailscale-oauth-secret || secrets.TAILSCALE_OAUTH_SECRET }}
          tailscale-tags: ${{ inputs.tailscale-tags || vars.TAILSCALE_TAGS }}

      - name: Helmfile run tests
        id: pytest
        # https://github.com/helmfile/helmfile-action
        uses: helmfile/helmfile-action@712000e3d4e28c72778ecc53857746082f555ef3 # v2.0.4
        with:
          helmfile-args: |
            apply \
              --environment ${{ vars.ENVIRONMENT }} \
              -f ${{ inputs.acapy-test-helmfile-path || './helm/acapy-test.yaml.gotmpl' }} \
              --set image.tag=${{ inputs.image-version }} \
              --set image.registry=ghcr.io/${{ github.repository_owner }} \
              --set completions=1 \
              --state-values-set release=acapy-test \
              --set fullnameOverride=acapy-test \
              --state-values-set namespace=${{ inputs.namespace || 'acapy-cloud-dev' }}
          helm-plugins: ${{ inputs.helm-plugins || 'https://github.com/databus23/helm-diff' }}
          helmfile-version: ${{ inputs.helmfile-version || env.HELMFILE_VERSION_DEFAULT }}
          helm-version: ${{ inputs.helm-version || env.HELM_VERSION_DEFAULT }}

      - name: Wait for tests and print logs
        if: steps.pytest.outcome == 'success'
        shell: bash
        run: |
          while true; do
            # Check if the job is complete or failed
            COMPLETION_STATUS=$(kubectl get job $JOB_NAME -n $NAMESPACE -o jsonpath='{.status.succeeded}')
            FAILURE_STATUS=$(kubectl get job $JOB_NAME -n $NAMESPACE -o jsonpath='{.status.failed}')

            if [ "$COMPLETION_STATUS" == "${PYTEST_COMPLETIONS}" ] || [ "$FAILURE_STATUS" == "1" ]; then
                echo "Job $JOB_NAME has completed."
                break
            else
                echo "Waiting for $JOB_NAME to complete..."
                sleep 10
            fi
          done

          # Get all pods for the job
          pods=$(kubectl get pods -n $NAMESPACE --selector=job-name=$JOB_NAME -o jsonpath='{.items[*].metadata.name}')

          # Loop through the pods and get logs
          for pod in $pods
          do
              echo "Logs for Pod: $pod"
              kubectl logs -n $NAMESPACE $pod
          done

        env:
          JOB_NAME: acapy-test
          NAMESPACE: ${{ inputs.namespace || 'acapy-cloud-dev' }}
          PYTEST_COMPLETIONS: 1

      - name: Copy test results
        if: steps.pytest.outcome == 'success'
        shell: bash
        run: |
          echo "apiVersion: v1
          kind: Pod
          metadata:
            name: $POD_NAME
            namespace: $NAMESPACE
            labels:
              sidecar.istio.io/inject: \"false\"
          spec:
            containers:
            - name: $POD_NAME
              image: $CONTAINER_IMAGE
              command:
              - sleep
              - inf
              volumeMounts:
              - name: pytest-volume
                mountPath: $MOUNT_PATH/pytest
            volumes:
            - name: pytest-volume
              persistentVolumeClaim:
                claimName: $PVC_NAME
            restartPolicy: Never
            terminationGracePeriodSeconds: 5" > pytest-results-pod.yaml

          kubectl apply -f pytest-results-pod.yaml

          # Wait for the pod to be ready
          echo "Waiting for pod to be ready..."
          kubectl -n $NAMESPACE wait --for=condition=ready pod/$POD_NAME --timeout=60s

          # Copy the files from the pod to your local system
          echo "Copying files from pod..."
          mkdir -p $LOCAL_PATH
          kubectl -n $NAMESPACE cp $POD_NAME:$MOUNT_PATH/pytest/$OUTPUT_FILE $LOCAL_PATH/$OUTPUT_FILE
          kubectl -n $NAMESPACE cp $POD_NAME:$MOUNT_PATH/pytest/$COVERAGE_FILE $LOCAL_PATH/$COVERAGE_FILE

          # Clean up: delete the temporary pod
          echo "Cleaning up..."
          kubectl -n $NAMESPACE delete pod $POD_NAME

          echo "Done!"
        env:
          PVC_NAME: acapy-test
          POD_NAME: pytest-results
          CONTAINER_IMAGE: busybox
          MOUNT_PATH: /mnt
          LOCAL_PATH: ./pytest
          NAMESPACE: ${{ inputs.namespace || 'acapy-cloud-dev' }}
          OUTPUT_FILE: test_output.xml
          COVERAGE_FILE: test_coverage.txt

      - name: Create/Update test coverage comment
        if: steps.pytest.outcome == 'success'
        # https://github.com/MishaKav/pytest-coverage-comment
        uses: MishaKav/pytest-coverage-comment@13d3c18e21895566c746187c9ea74736372e5e91 # v1.1.54
        with:
          pytest-coverage-path: ./pytest/test_coverage.txt
          junitxml-path: ./pytest/test_output.xml
          title: EKS E2E Test Coverage
          # Resolves `Warning: Your comment is too long (maximum is 65536 characters), coverage report will not be added.`
          hide-report: ${{ github.event_name != 'pull_request' }}
          hide-comment: ${{ github.event_name != 'pull_request' }}

      - name: Publish test report
        # https://github.com/mikepenz/action-junit-report
        uses: mikepenz/action-junit-report@65fe03598d8d251738592a497a9e8547a5c48eaa # v5.6.0
        if: steps.pytest.outcome == 'success'
        with:
          check_name: JUnit E2E Test Report
          report_paths: ./pytest/test_output.xml
          fail_on_failure: true
          detailed_summary: true
          require_passed_tests: true

      - name: Helmfile Destroy
        # https://github.com/helmfile/helmfile-action
        uses: helmfile/helmfile-action@712000e3d4e28c72778ecc53857746082f555ef3 # v2.0.4
        if: always()
        with:
          helmfile-args: |
            destroy \
              --environment ${{ vars.ENVIRONMENT }} \
              -f ${{ inputs.acapy-test-helmfile-path || './helm/acapy-test.yaml.gotmpl' }} \
              --state-values-set release=acapy-test
          helm-plugins: ${{ inputs.helm-plugins || 'https://github.com/databus23/helm-diff' }}
          helmfile-version: ${{ inputs.helmfile-version || env.HELMFILE_VERSION_DEFAULT }}
          helm-version: ${{ inputs.helm-version || env.HELM_VERSION_DEFAULT }}

  test-regression:
    name: Tests / Regression
    needs: deploy
    if: inputs.run-regression-tests
    runs-on: ubuntu-latest

    timeout-minutes: 30

    environment:
      name: dev

    permissions:
      id-token: write # Required to authenticate with AWS
      checks: write # Required for action-junit-report
      pull-requests: write # Required to comment on PRs for Pytest coverage comment

    steps:
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: false

      - name: Connect to EKS
        uses: didx-xyz/workflows/connect-eks@db85590d7cdd99f3eb257b0526d905263eca8499 # master
        with:
          aws-region: af-south-1
          aws-role-arn: arn:aws:iam::402177810328:role/cicd
          aws-role-session-name: github-cicd
          cluster-name: cloudapi-dev
          tailscale-oauth-client-id: ${{ secrets.tailscale-oauth-client-id || secrets.TAILSCALE_OAUTH_CLIENT_ID }}
          tailscale-oauth-secret: ${{ secrets.tailscale-oauth-secret || secrets.TAILSCALE_OAUTH_SECRET }}
          tailscale-tags: ${{ inputs.tailscale-tags || vars.TAILSCALE_TAGS }}

      - name: Helmfile run tests
        id: regression
        # https://github.com/helmfile/helmfile-action
        uses: helmfile/helmfile-action@712000e3d4e28c72778ecc53857746082f555ef3 # v2.0.4
        with:
          helmfile-args: |
            apply \
              --environment ${{ vars.ENVIRONMENT }} \
              -f ${{ inputs.acapy-test-helmfile-path || './helm/acapy-test.yaml.gotmpl' }} \
              --set image.tag=${{ inputs.image-version }} \
              --set image.registry=ghcr.io/${{ github.repository_owner }} \
              --set completions=1 \
              --state-values-set release=acapy-test-regression \
              --set fullnameOverride=acapy-test-regression \
              --set env.RUN_REGRESSION_TESTS=true \
              --set env.FAIL_ON_RECREATING_FIXTURES=${{ inputs.reset-deployments == false }} \
              --state-values-set regressionEnabled=true \
              --state-values-set namespace=${{ inputs.namespace || 'acapy-cloud-dev' }}
          helm-plugins: ${{ inputs.helm-plugins || 'https://github.com/databus23/helm-diff' }}
          helmfile-version: ${{ inputs.helmfile-version || env.HELMFILE_VERSION_DEFAULT }}
          helm-version: ${{ inputs.helm-version || env.HELM_VERSION_DEFAULT }}

      - name: Wait for tests and print logs
        if: steps.regression.outcome == 'success'
        shell: bash
        run: |
          while true; do
            # Check if the job is complete or failed
            COMPLETION_STATUS=$(kubectl get job $JOB_NAME -n $NAMESPACE -o jsonpath='{.status.succeeded}')
            FAILURE_STATUS=$(kubectl get job $JOB_NAME -n $NAMESPACE -o jsonpath='{.status.failed}')

            if [ "$COMPLETION_STATUS" == "${PYTEST_COMPLETIONS}" ] || [ "$FAILURE_STATUS" == "1" ]; then
                echo "Job $JOB_NAME has completed."
                break
            else
                echo "Waiting for $JOB_NAME to complete..."
                sleep 10
            fi
          done

          # Get all pods for the job
          pods=$(kubectl get pods -n $NAMESPACE --selector=job-name=$JOB_NAME -o jsonpath='{.items[*].metadata.name}')

          # Loop through the pods and get logs
          for pod in $pods
          do
              echo "Logs for Pod: $pod"
              kubectl logs -n $NAMESPACE $pod
          done

        env:
          JOB_NAME: acapy-test-regression
          NAMESPACE: ${{ inputs.namespace || 'acapy-cloud-dev' }}
          PYTEST_COMPLETIONS: 1

      - name: Copy test results
        if: steps.regression.outcome == 'success'
        shell: bash
        run: |
          echo "apiVersion: v1
          kind: Pod
          metadata:
            name: $POD_NAME
            namespace: $NAMESPACE
            labels:
              sidecar.istio.io/inject: \"false\"
          spec:
            containers:
            - name: $POD_NAME
              image: $CONTAINER_IMAGE
              command:
              - sleep
              - inf
              volumeMounts:
              - name: pytest-regression-volume
                mountPath: $MOUNT_PATH/pytest-regression
            volumes:
            - name: pytest-regression-volume
              persistentVolumeClaim:
                claimName: $PVC_NAME_REGRESSION
            restartPolicy: Never
            terminationGracePeriodSeconds: 5" > pytest-results-pod.yaml

          kubectl apply -f pytest-results-pod.yaml

          # Wait for the pod to be ready
          echo "Waiting for pod to be ready..."
          kubectl -n $NAMESPACE wait --for=condition=ready pod/$POD_NAME --timeout=60s

          # Copy the files from the pod to your local system
          echo "Copying files from pod..."
          mkdir -p $LOCAL_PATH_REGRESSION
          kubectl -n $NAMESPACE cp $POD_NAME:$MOUNT_PATH/pytest-regression/$OUTPUT_FILE $LOCAL_PATH_REGRESSION/$OUTPUT_FILE
          kubectl -n $NAMESPACE cp $POD_NAME:$MOUNT_PATH/pytest-regression/$COVERAGE_FILE $LOCAL_PATH_REGRESSION/$COVERAGE_FILE

          # Clean up: delete the temporary pod
          echo "Cleaning up..."
          kubectl -n $NAMESPACE delete pod $POD_NAME

          echo "Done!"
        env:
          PVC_NAME_REGRESSION: acapy-test-regression
          POD_NAME: pytest-regression-results
          CONTAINER_IMAGE: busybox
          MOUNT_PATH: /mnt
          LOCAL_PATH_REGRESSION: ./pytest-regression
          NAMESPACE: ${{ inputs.namespace || 'acapy-cloud-dev' }}
          OUTPUT_FILE: test_output.xml
          COVERAGE_FILE: test_coverage.txt
          hide-comment: ${{ github.event_name != 'pull_request' }}

      - name: Create/Update test coverage comment
        if: steps.regression.outcome == 'success'
        # https://github.com/MishaKav/pytest-coverage-comment
        uses: MishaKav/pytest-coverage-comment@13d3c18e21895566c746187c9ea74736372e5e91 # v1.1.54
        with:
          pytest-coverage-path: ./pytest-regression/test_coverage.txt
          junitxml-path: ./pytest-regression/test_output.xml
          title: EKS Regression Test Coverage
          # Resolves `Warning: Your comment is too long (maximum is 65536 characters), coverage report will not be added.`
          hide-report: ${{ github.event_name != 'pull_request' }}
          hide-comment: ${{ github.event_name != 'pull_request' }}

      - name: Publish test report
        uses: mikepenz/action-junit-report@65fe03598d8d251738592a497a9e8547a5c48eaa # v5.6.0
        if: steps.regression.outcome == 'success'
        with:
          check_name: JUnit Regression Test Report
          report_paths: ./pytest-regression/test_output.xml
          fail_on_failure: true
          detailed_summary: true
          require_passed_tests: true

      - name: Helmfile destroy
        # https://github.com/helmfile/helmfile-action
        uses: helmfile/helmfile-action@712000e3d4e28c72778ecc53857746082f555ef3 # v2.0.4
        if: always()
        with:
          helmfile-args: |
            destroy \
              --environment ${{ vars.ENVIRONMENT }} \
              -f ${{ inputs.acapy-test-helmfile-path || './helm/acapy-test.yaml.gotmpl' }} \
              --state-values-set release=acapy-test-regression \
              --state-values-set namespace=${{ inputs.namespace || 'acapy-cloud-dev' }}
          helm-plugins: ${{ inputs.helm-plugins || 'https://github.com/databus23/helm-diff' }}
          helmfile-version: ${{ inputs.helmfile-version || env.HELMFILE_VERSION_DEFAULT }}
          helm-version: ${{ inputs.helm-version || env.HELM_VERSION_DEFAULT }}

  test-k6:
    name: Tests / K6
    needs: deploy
    if: inputs.run-k6-tests
    runs-on: ubuntu-latest

    timeout-minutes: 30

    environment:
      name: dev

    permissions:
      id-token: write # Required to authenticate with AWS

    steps:
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: false

      - name: Connect to EKS
        uses: didx-xyz/workflows/connect-eks@db85590d7cdd99f3eb257b0526d905263eca8499 # master
        with:
          aws-region: af-south-1
          aws-role-arn: arn:aws:iam::402177810328:role/cicd
          aws-role-session-name: github-cicd
          cluster-name: cloudapi-dev
          tailscale-oauth-client-id: ${{ secrets.tailscale-oauth-client-id || secrets.TAILSCALE_OAUTH_CLIENT_ID }}
          tailscale-oauth-secret: ${{ secrets.tailscale-oauth-secret || secrets.TAILSCALE_OAUTH_SECRET }}
          tailscale-tags: ${{ inputs.tailscale-tags || vars.TAILSCALE_TAGS }}

      - name: Prepare output directory
        run: mkdir -p ${{ github.workspace }}/scripts/k6/output && chmod 777 ${{ github.workspace }}/scripts/k6/output

      - name: Run k6 tests
        run: |
          docker run --rm --network=host \
            -v ${{ github.workspace }}/scripts/k6:/scripts \
            -e CLOUDAPI_URL="https://acapy-cloud.dev.didxtech.com" \
            -e GOVERNANCE_API_KEY="adminApiKey" \
            -e TENANT_ADMIN_API_KEY="adminApiKey" \
            --workdir /scripts \
            --entrypoint /bin/sh \
            ghcr.io/${{ github.repository_owner }}/acapy-cloud/xk6:${VERSION} \
            /scripts/run_tests.sh
        shell: bash
        env:
          VERSION: ${{ inputs.image-version }}
