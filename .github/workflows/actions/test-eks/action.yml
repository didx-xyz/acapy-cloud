name: Test EKS
description: Run Tests against EKS

inputs:
  clean-start:
    description: Whether this is a clean start or not
    required: false
    default: "false"
  environment:
    description: The environment to deploy to
    required: true
  helm-version:
    description: The version of Helm to use
    required: true
  helmfile-path:
    description: The path to the Helmfile to use
    required: false
    default: ./helm/acapy-test.yaml.gotmpl
  helmfile-plugins:
    description: The Helmfile plugins to install
    required: false
    default: https://github.com/databus23/helm-diff
  helmfile-version:
    description: The version of Helmfile to use
    required: true
  image-tag:
    description: The tag of the Docker image to deploy
    required: true
  mise-version:
    description: "The version of Mise to use"
    required: true
  namespace:
    description: The Kubernetes namespace to deploy to
    required: true
  pytest-completions:
    description: How many completions to run
    required: false
    default: "1"
  regression-tests:
    description: Whether to run regression tests
    required: false
    default: "true"
  run-tests:
    description: Whether to run tests
    required: false
    default: "true"

runs:
  using: composite

  steps:
    - name: Helmfile run regression tests
      if: inputs.regression-tests == 'true'
      id: pytest-regression
      # https://github.com/helmfile/helmfile-action
      uses: helmfile/helmfile-action@712000e3d4e28c72778ecc53857746082f555ef3 # v2.0.4
      with:
        helmfile-args: |
          apply \
            --environment ${{ inputs.environment }} \
            -f ${{ inputs.helmfile-path }} \
            --set image.tag=${{ inputs.image-tag }} \
            --set image.registry=ghcr.io/${{ github.repository_owner }} \
            --set completions=${{ inputs.pytest-completions }} \
            --state-values-set release=acapy-test-regression \
            --set fullnameOverride=acapy-test-regression \
            --set env.RUN_REGRESSION_TESTS=${{ inputs.regression-tests }} \
            --set env.FAIL_ON_RECREATING_FIXTURES=${{ inputs.clean-start != 'true' }} \
            --state-values-set regressionEnabled=${{ inputs.regression-tests }} \
            --state-values-set namespace=${{ inputs.namespace }}
        helm-plugins: ${{ inputs.helmfile-plugins }}
        helmfile-version: ${{ inputs.helmfile-version }}
        helm-version: ${{ inputs.helm-version }}

    - name: Helmfile run pytest
      if: inputs.run-tests != 'false'
      id: pytest
      # https://github.com/helmfile/helmfile-action
      uses: helmfile/helmfile-action@712000e3d4e28c72778ecc53857746082f555ef3 # v2.0.4
      with:
        helmfile-args: |
          apply \
            --environment ${{ inputs.environment }} \
            -f ${{ inputs.helmfile-path }} \
            --set image.tag=${{ inputs.image-tag }} \
            --set image.registry=ghcr.io/${{ github.repository_owner }} \
            --set completions=${{ inputs.pytest-completions }} \
            --state-values-set release=acapy-test \
            --set fullnameOverride=acapy-test \
            --state-values-set namespace=${{ inputs.namespace }}
        helm-plugins: ${{ inputs.helmfile-plugins }}
        helmfile-version: ${{ inputs.helmfile-version }}
        helm-version: ${{ inputs.helm-version }}

    - name: Wait for pytest and print logs
      if: steps.pytest.outcome == 'success'
      shell: bash
      run: |
        while true; do
          # Check if the job is complete or failed
          COMPLETION_STATUS=$(kubectl get job $JOB_NAME -n $NAMESPACE -o jsonpath='{.status.succeeded}')
          FAILURE_STATUS=$(kubectl get job $JOB_NAME -n $NAMESPACE -o jsonpath='{.status.failed}')

          if [ "$COMPLETION_STATUS" == "${PYTEST_COMPLETIONS}" ] || [ "$FAILURE_STATUS" == "1" ]; then
              echo "Job $JOB_NAME has completed."
              break
          else
              echo "Waiting for $JOB_NAME to complete..."
              sleep 10
          fi
        done

        # Get all pods for the job
        pods=$(kubectl get pods -n $NAMESPACE --selector=job-name=$JOB_NAME -o jsonpath='{.items[*].metadata.name}')

        # Loop through the pods and get logs
        for pod in $pods
        do
            echo "Logs for Pod: $pod"
            kubectl logs -n $NAMESPACE $pod
        done

      env:
        JOB_NAME: acapy-test
        NAMESPACE: ${{ inputs.namespace }}
        PYTEST_COMPLETIONS: ${{ inputs.pytest-completions }}

    - name: Wait for pytest regression and print logs
      if: steps.pytest-regression.outcome == 'success'
      shell: bash
      run: |
        while true; do
          # Check if the job is complete or failed
          COMPLETION_STATUS=$(kubectl get job $JOB_NAME -n $NAMESPACE -o jsonpath='{.status.succeeded}')
          FAILURE_STATUS=$(kubectl get job $JOB_NAME -n $NAMESPACE -o jsonpath='{.status.failed}')

          if [ "$COMPLETION_STATUS" == "${PYTEST_COMPLETIONS}" ] || [ "$FAILURE_STATUS" == "1" ]; then
              echo "Job $JOB_NAME has completed."
              break
          else
              echo "Waiting for $JOB_NAME to complete..."
              sleep 10
          fi
        done

        # Get all pods for the job
        pods=$(kubectl get pods -n $NAMESPACE --selector=job-name=$JOB_NAME -o jsonpath='{.items[*].metadata.name}')

        # Loop through the pods and get logs
        for pod in $pods
        do
            echo "Logs for Pod: $pod"
            kubectl logs -n $NAMESPACE $pod
        done

      env:
        JOB_NAME: acapy-test-regression
        NAMESPACE: ${{ inputs.namespace }}
        PYTEST_COMPLETIONS: ${{ inputs.pytest-completions }}

    - name: Copy k8s pytest results
      if: steps.pytest.outcome == 'success' || steps.pytest-regression.outcome == 'success'
      shell: bash
      run: |
        echo "apiVersion: v1
        kind: Pod
        metadata:
          name: $POD_NAME
          namespace: $NAMESPACE
          labels:
            sidecar.istio.io/inject: \"false\"
        spec:
          containers:
          - name: $POD_NAME
            image: $CONTAINER_IMAGE
            command:
            - sleep
            - inf
            volumeMounts:
            - name: pytest-volume
              mountPath: $MOUNT_PATH/pytest
            - name: pytest-regression-volume
              mountPath: $MOUNT_PATH/pytest-regression
          volumes:
          - name: pytest-volume
            persistentVolumeClaim:
              claimName: $PVC_NAME
          - name: pytest-regression-volume
            persistentVolumeClaim:
              claimName: $PVC_NAME_REGRESSION
          restartPolicy: Never
          terminationGracePeriodSeconds: 5" > pytest-results-pod.yaml

        kubectl apply -f pytest-results-pod.yaml

        # Wait for the pod to be ready
        echo "Waiting for pod to be ready..."
        kubectl -n $NAMESPACE wait --for=condition=ready pod/$POD_NAME --timeout=60s

        # Copy the files from the pod to your local system
        echo "Copying files from pod..."
        mkdir -p $LOCAL_PATH $LOCAL_PATH_REGRESSION
        kubectl -n $NAMESPACE cp $POD_NAME:$MOUNT_PATH/pytest/$OUTPUT_FILE $LOCAL_PATH/$OUTPUT_FILE
        kubectl -n $NAMESPACE cp $POD_NAME:$MOUNT_PATH/pytest/$COVERAGE_FILE $LOCAL_PATH/$COVERAGE_FILE
        kubectl -n $NAMESPACE cp $POD_NAME:$MOUNT_PATH/pytest-regression/$OUTPUT_FILE $LOCAL_PATH_REGRESSION/$OUTPUT_FILE
        kubectl -n $NAMESPACE cp $POD_NAME:$MOUNT_PATH/pytest-regression/$COVERAGE_FILE $LOCAL_PATH_REGRESSION/$COVERAGE_FILE

        # Clean up: delete the temporary pod
        echo "Cleaning up..."
        kubectl -n $NAMESPACE delete pod $POD_NAME

        echo "Done!"
      env:
        PVC_NAME: acapy-test
        PVC_NAME_REGRESSION: acapy-test-regression
        POD_NAME: pytest-results-pod
        CONTAINER_IMAGE: busybox
        MOUNT_PATH: /mnt
        LOCAL_PATH: ./pytest
        LOCAL_PATH_REGRESSION: ./pytest-regression
        NAMESPACE: ${{ inputs.namespace }}
        OUTPUT_FILE: test_output.xml
        COVERAGE_FILE: test_coverage.txt

    - name: Pytest coverage comment
      if: steps.pytest.outcome == 'success'
      # https://github.com/MishaKav/pytest-coverage-comment
      uses: MishaKav/pytest-coverage-comment@13d3c18e21895566c746187c9ea74736372e5e91 # v1.1.54
      with:
        pytest-coverage-path: ./pytest/test_coverage.txt
        junitxml-path: ./pytest/test_output.xml
        create-new-comment: true
        title: "K8s Test Coverage"
        # Resolves `Warning: Your comment is too long (maximum is 65536 characters), coverage report will not be added.`
        hide-report: ${{ github.event_name != 'pull_request' }}
        hide-comment: ${{ github.event_name != 'pull_request' }}

    - name: Pytest regression coverage comment
      if: steps.pytest-regression.outcome == 'success'
      # https://github.com/MishaKav/pytest-coverage-comment
      uses: MishaKav/pytest-coverage-comment@13d3c18e21895566c746187c9ea74736372e5e91 # v1.1.54
      with:
        pytest-coverage-path: ./pytest-regression/test_coverage.txt
        junitxml-path: ./pytest-regression/test_output.xml
        create-new-comment: true
        title: "K8s Regression Test Coverage"
        # Resolves `Warning: Your comment is too long (maximum is 65536 characters), coverage report will not be added.`
        hide-report: ${{ github.event_name != 'pull_request' }}
        hide-comment: ${{ github.event_name != 'pull_request' }}

    - name: Publish Pytest Report
      # https://github.com/mikepenz/action-junit-report
      uses: mikepenz/action-junit-report@cf701569b05ccdd861a76b8607a66d76f6fd4857 # v5.5.1
      if: steps.pytest.outcome == 'success'
      with:
        check_name: JUnit Test Report
        report_paths: "./pytest/test_output.xml"
        fail_on_failure: true
        detailed_summary: true
        require_passed_tests: true

    - name: Publish Pytest Regression Report
      uses: mikepenz/action-junit-report@cf701569b05ccdd861a76b8607a66d76f6fd4857 # v5.5.1
      if: steps.pytest-regression.outcome == 'success'
      with:
        check_name: JUnit Test Report Regression
        report_paths: "./pytest-regression/test_output.xml"
        fail_on_failure: true
        detailed_summary: true
        require_passed_tests: true

    - name: Helmfile destroy pytest
      # https://github.com/helmfile/helmfile-action
      uses: helmfile/helmfile-action@712000e3d4e28c72778ecc53857746082f555ef3 # v2.0.4
      if: always()
      with:
        helmfile-args: |
          destroy \
            --environment ${{ inputs.environment }} \
            -f ${{ inputs.helmfile-path }} \
            --state-values-set release=acapy-test
        helm-plugins: ${{ inputs.helmfile-plugins }}
        helmfile-version: ${{ inputs.helmfile-version }}
        helm-version: ${{ inputs.helm-version }}

    - name: Helmfile destroy pytest regression
      # https://github.com/helmfile/helmfile-action
      uses: helmfile/helmfile-action@712000e3d4e28c72778ecc53857746082f555ef3 # v2.0.4
      if: always()
      with:
        helmfile-args: |
          destroy \
            --environment ${{ inputs.environment }} \
            -f ${{ inputs.helmfile-path }} \
            --state-values-set release=acapy-test-regression \
            --state-values-set namespace=${{ inputs.namespace }}
        helm-plugins: ${{ inputs.helmfile-plugins }}
        helmfile-version: ${{ inputs.helmfile-version }}
        helm-version: ${{ inputs.helm-version }}
